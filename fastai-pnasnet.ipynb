{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukkin image dataset nya disini, tapi per folder harus ada labelnya\n",
    "#Reference Implementation fastai --->>> https://gilberttanner.com/blog/fastai-image-classification\n",
    "\n",
    "tfms = get_transforms(max_lighting=0.4, max_zoom=1.2, max_warp=0.2, max_rotate=20, xtra_tfms=[flip_lr()])\n",
    "defaults.device = torch.device(\"cuda\")\n",
    "data = ImageDataBunch.from_folder(Path('./dataset'),\n",
    "                                  train = 'train/',\n",
    "                                  valid_pct = 0.1,\n",
    "                                  resize_method=ResizeMethod.SQUISH, \n",
    "                                  ds_tfms = tfms,\n",
    "                                  size = 299,\n",
    "                                  bs = 32,\n",
    "                                  num_workers = 50\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch(rows=3, figsize=(7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data.classes), data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1., gamma=2.):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets, **kwargs):\n",
    "        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-CE_loss)\n",
    "        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n",
    "        return F_loss.mean()\n",
    "    \n",
    "    \n",
    "# model nyta buat cnn_learner\n",
    "def senet(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.senet154(pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))\n",
    "\n",
    "def identity(x): return x\n",
    "\n",
    "def pnasnet5large(pretrained=False):    \n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = pretrainedmodels.pnasnet5large(pretrained=pretrained, num_classes=1000) \n",
    "    model.logits = identity\n",
    "    return nn.Sequential(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/checkpoints/efficientnet-b3-5fb5a3c3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cf70e440d84394bfe30de99be32b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=49388949.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def get_model(pretrained=True, **kwargs): \n",
    "    model = EfficientNet.from_pretrained('efficientnet-b3')\n",
    "    model._fc = nn.Linear(model._fc.in_features, data.c) # check the top most layer\n",
    "    return model \n",
    "\n",
    "learn = Learner(data, get_model(),\n",
    "               metrics = [accuracy], \n",
    "               wd=.1, \n",
    "               path='.').mixup().to_fp16() # because different clf layer, we use Learner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fastai --->>> https://docs.fast.ai/vision.models.html\n",
    "# best practice: start small, \n",
    "# baru ganti model IF tuning hyperparameter udah gak improved.\n",
    "learn = cnn_learner(data, \n",
    "                    senet, \n",
    "                    pretrained=True, \n",
    "                    cut=-2, \n",
    "                    metrics = [accuracy]\n",
    "                   )\n",
    "learn.loss_fn = FocalLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fastai --->>> https://docs.fast.ai/vision.models.html\n",
    "# best practice: start small, \n",
    "# baru ganti model IF tuning hyperparameter udah gak improved.\n",
    "learn = cnn_learner(data, \n",
    "                    pnasnet5large, \n",
    "                    metrics = accuracy, \n",
    "                    cut=None\n",
    "                   )\n",
    "learn.loss_fn = FocalLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='3307' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/3307 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)\n",
    "min_grad_lr = learn.recorder.min_grad_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(4, max_lr=slice(min_grad_lr/10, min_grad_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b3');\n",
    "learn.unfreeze();\n",
    "learn = learn.clip_grad();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('b3');\n",
    "learn.unfreeze();\n",
    "learn = learn.clip_grad();\n",
    "min_grad_lr = learn.recorder.min_grad_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "learn.fit_one_cycle(12, slice(min_grad_lr/10 min_grad_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('senet')\n",
    "learn.export('senet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using ResNeXt-101-32x8d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretrainedmodels\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1., gamma=2.):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets, **kwargs):\n",
    "        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-CE_loss)\n",
    "        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n",
    "        return F_loss.mean()\n",
    "    \n",
    "# model nyta buat cnn_learner\n",
    "def resnext101_32x8d(pretrained=False):\n",
    "    pretrained = 'imagenet' if pretrained else None\n",
    "    model = bn.resnext101_32x8d(pretrained=pretrained)\n",
    "    return nn.Sequential(*list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model fastai --->>> https://docs.fast.ai/vision.models.html\n",
    "# best practice: start small, \n",
    "# baru ganti model IF tuning hyperparameter udah gak improved.\n",
    "learn = cnn_learner(data, \n",
    "                    resnext50_32x4d, \n",
    "                    pretrained=True, \n",
    "                    cut=-2, \n",
    "                    metrics = [accuracy]\n",
    "                   )\n",
    "learn.loss_fn = FocalLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(32, max_lr=slice(2e-2), wd=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('resnext101_32x8d');\n",
    "learn.unfreeze();\n",
    "learn = learn.clip_grad();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
