{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## augmentation \n",
    "- resize to a n * n dimension, using squished method (stretched)\n",
    "- randomize: brightness, zoom, warp when rotated, and flip\n",
    "\n",
    "## model\n",
    "efnet b0, b5 then assemble\n",
    "\n",
    "## training method\n",
    "fastai with efficient + progressive training + fp16\n",
    "then progressively trained from 128, 256, 368, 468 with 64,64,64,32,16 batch size respectively\n",
    "\n",
    "## loss function \n",
    "FocalLoss -> label smoothing cross entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate\n",
    "from fastai.callbacks import *\n",
    "from fastai.vision.models.efficientnet import *\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#masukkin image dataset nya disini, tapi per folder harus ada labelnya\n",
    "#Reference Implementation fastai --->>> https://gilberttanner.com/blog/fastai-image-classification\n",
    "defaults.device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs, size): \n",
    "    tfms = get_transforms(max_lighting=0.4, max_zoom=1.2, max_warp=0.2, max_rotate=20, xtra_tfms=[flip_lr()])\n",
    "    return ImageDataBunch.from_folder(Path('./dataset'),\n",
    "                                  train = 'train/',\n",
    "                                  valid_pct = 0.1,\n",
    "                                  resize_method=ResizeMethod.SQUISH, \n",
    "                                  ds_tfms = tfms,\n",
    "                                  size = size,\n",
    "                                  bs = bs,\n",
    "                                  num_workers = 50\n",
    "                                  ).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_data(64, 128)\n",
    "\n",
    "len(data.classes), data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model._fc = nn.Linear(model._fc.in_features, data.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "def get_model(pretrained=True, **kwargs): \n",
    "    model = EfficientNet.from_pretrained('efficientnet-b0')\n",
    "    model._fc = nn.Linear(model._fc.in_features, data.c) # check the top most layer\n",
    "    return model \n",
    "\n",
    "def stage1(learn, data=None, epoch = 5):\n",
    "    if data: \n",
    "        learn.data=data\n",
    "        learn.to_fp16()\n",
    "        \n",
    "    learn.freeze()\n",
    "    learn.fit_one_cycle(epoch)\n",
    "    \n",
    "def stage2(learn, load_filename=None, epoch=5):\n",
    "    if load_filename: \n",
    "        learn.load(load_filename, purge=True)\n",
    "    learn.unfreeze()\n",
    "    learn.lr_find()\n",
    "    learn.recorder.plot(suggestion=True)\n",
    "    min_grad_lr = learn.recorder.min_grad_lr\n",
    "    learn.fit_one_cycle(epoch, slice(min_grad_lr/40, min_grad_lr))\n",
    "\n",
    "learn = Learner(data, model,\n",
    "               metrics = [accuracy], \n",
    "                bn_wd=False, #disable weight decay \n",
    "                loss_func = LabelSmoothingCrossEntropy(), \n",
    "                callback_fns=[BnFreeze,\n",
    "                             partial(SaveModelCallback, monitor='accuracy', name='most_accurate')],\n",
    "               path='./dataset').to_fp16() # because different clf layer, we use Learner.\n",
    "learn.split(lambda m: (model._conv_head,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1(learn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stage2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b5-epoch5-128')\n",
    "learn.load('b5-epoch5-128', purge=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(64, 256)\n",
    "learn.load('b5-epoch5-256', purge=True)\n",
    "learn.to_fp16()\n",
    "stage1(learn, data)\n",
    "stage2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b5-epoch5-256')\n",
    "learn.load('b5-epoch5-256', purge=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 368"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINI\n",
    "data = get_data(32, 368)\n",
    "learn.load('b0-epoch5-384', purge=True)\n",
    "learn.to_fp16()\n",
    "stage1(learn, data)\n",
    "stage2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b5-epoch5-368')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 468"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINI\n",
    "data = get_data(32, 368)\n",
    "learn.load('b0-epoch5-384', purge=True)\n",
    "learn.to_fp16()\n",
    "stage1(learn, data)\n",
    "stage2(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b5-epoch5-468')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('b5-epoch5-468', purge=True)\n",
    "data = get_data(16, 512)\n",
    "learn.load('b5-epoch5-468', purge=True)\n",
    "learn.data=data\n",
    "learn.to_fp16()\n",
    "stage1(learn, data)\n",
    "stage2(learn,epoch=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('b0 final ')\n",
    "learn.export('b0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = get_data(16, 512)\n",
    "learn.load('b0 final ', purge=True)\n",
    "learn.data = data\n",
    "learn.to_fp16()\n",
    "stage1(learn,epoch=6)\n",
    "learn.save('b0 final-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('python finish_me.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('b5-epoch5-468', purge=True)\n",
    "# stage1(learn, data)\n",
    "learn.load('b0 final-1')\n",
    "data = get_data(16, 512)\n",
    "\n",
    "learn.data=data\n",
    "learn.to_fp16()\n",
    "\n",
    "# stage2(learn,epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('python finish_me.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('b0 final-1')\n",
    "data = get_data(16, 512)\n",
    "\n",
    "learn.data=data\n",
    "learn.to_fp32()\n",
    "\n",
    "\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner('./dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = open_image('./bag.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.train_ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_prediksi = learn.predict(image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(hasil_prediksi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'apply_tfms',\n",
       " 'data',\n",
       " 'obj',\n",
       " 'show']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(hasil_prediksi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Category tensor(9), tensor(9), tensor([ 8.7969,  8.5134,  9.4475, 10.5954,  7.6278,  7.9949,  8.6377,  8.9289,\n",
      "        11.5912, 16.6772,  8.0053,  8.6517,  7.4771,  8.9308,  8.0464,  8.9818,\n",
      "         8.7663,  8.5720,  8.4165,  8.9928,  7.5449,  9.9747, 10.0802,  9.8516,\n",
      "         8.9836,  8.9228,  8.3149,  9.1229,  8.6906,  6.4960,  6.9768,  8.8049,\n",
      "         6.2074,  7.8944,  7.4179,  8.3689,  9.2012, 11.5521,  6.6051, 10.1046,\n",
      "         7.0696,  7.6125]))\n"
     ]
    }
   ],
   "source": [
    "print(hasil_prediksi) # ini kenapa ada 3 prediksi anjir fak\n",
    "\"\"\"\n",
    "It returns a tuple of three things: \n",
    "the object predicted (with the class in this instance), \n",
    "the underlying data (here the corresponding index)  \n",
    "the raw probabilities. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(hasil_prediksi[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(learn, filename):\n",
    "    log_preds, test_labels = learn.get_preds(ds_type=DatasetType.Test)\n",
    "    preds = np.argmax(log_preds, 1)\n",
    "    a = np.array(preds)\n",
    "    submission = pd.DataFrame({'image_name': os.listdir('data/test'), 'label': a})\n",
    "    submission.to_csv(path/filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
