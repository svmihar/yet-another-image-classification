{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations > /dev/null\n",
    "!pip install -U git+https://github.com/qubvel/efficientnet\n",
    "!pip install console_progressbar\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# buat test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.pooling import MaxPooling2D,AveragePooling2D\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "\n",
    "import keras.callbacks as callbacks\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "import efficientnet.keras as efn \n",
    "from efficientnet.keras import center_crop_and_resize, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_acc(history):\n",
    "    plt.figure(figsize=(20,7))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'][1:])    \n",
    "    plt.plot(history.history['val_loss'][1:])    \n",
    "    plt.title('model loss')    \n",
    "    plt.ylabel('val_loss')    \n",
    "    plt.xlabel('epoch')    \n",
    "    plt.legend(['Train','Validation'], loc='upper left')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['acc'][1:])\n",
    "    plt.plot(history.history['val_acc'][1:])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('val_acc')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['Train','Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    \n",
    "class SnapshotCallbackBuilder:\n",
    "    def __init__(self, nb_epochs, nb_snapshots, init_lr=0.1):\n",
    "        self.T = nb_epochs\n",
    "        self.M = nb_snapshots\n",
    "        self.alpha_zero = init_lr\n",
    "\n",
    "    def get_callbacks(self, model_prefix='Model'):\n",
    "\n",
    "        callback_list = [\n",
    "            swa,\n",
    "            callbacks.LearningRateScheduler(schedule=self._cosine_anneal_schedule)\n",
    "        ]\n",
    "\n",
    "        return callback_list\n",
    "\n",
    "    def _cosine_anneal_schedule(self, t):\n",
    "        cos_inner = np.pi * (t % (self.T // self.M))  # t - 1 is used when t has 1-based indexing.\n",
    "        cos_inner /= self.T // self.M\n",
    "        cos_out = np.cos(cos_inner) + 1\n",
    "        return float(self.alpha_zero / 2 * cos_out)\n",
    "    \n",
    "class SWA(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, filepath, swa_epoch):\n",
    "        super(SWA, self).__init__()\n",
    "        self.filepath = filepath\n",
    "        self.swa_epoch = swa_epoch \n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.nb_epoch = self.params['epochs']\n",
    "        print('Stochastic weight averaging selected for last {} epochs.'\n",
    "              .format(self.nb_epoch - self.swa_epoch))\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        if epoch == self.swa_epoch:\n",
    "            self.swa_weights = self.model.get_weights()\n",
    "            \n",
    "        elif epoch > self.swa_epoch:    \n",
    "            for i in range(len(self.swa_weights)):\n",
    "                self.swa_weights[i] = (self.swa_weights[i] * \n",
    "                    (epoch - self.swa_epoch) + self.model.get_weights()[i])/((epoch - self.swa_epoch)  + 1)  \n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        self.model.set_weights(self.swa_weights)\n",
    "        print('Final model parameters set to stochastic weight average.')\n",
    "        self.model.save_weights(self.filepath)\n",
    "        print('Final stochastic averaged weights saved to file.')\n",
    "        \n",
    "def build_finetune_model(base_model, dropout, num_classes):\n",
    "\n",
    "    x = base_model.output\n",
    "    \n",
    "    x = AveragePooling2D((5, 5), name='avg_pool')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax', name='finalfc')(x)\n",
    "    \n",
    "    finetune_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    return finetune_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105392 images belonging to 42 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "HEIGHT = 299\n",
    "WIDTH = 299\n",
    "TARGET_SIZE = (HEIGHT, WIDTH)\n",
    "BS = 8\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        rotation_range=20.,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=[0.9, 1.25],\n",
    "        brightness_range=[0.5, 1.5],\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "TRAIN_FOLDER = \"./dataset/train/\"\n",
    "TEST_FOLDER = \"./dataset/test/\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_FOLDER, \n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BS,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        TEST_FOLDER,\n",
    "        target_size=TARGET_SIZE,\n",
    "        batch_size=BS,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Stochastic weight averaging selected for last 3 epochs.\n",
      "Epoch 1/200\n",
      " - 80s - loss: 3.5113 - accuracy: 0.1167\n",
      "Epoch 2/200\n",
      " - 49s - loss: 3.2242 - accuracy: 0.1867\n",
      "Epoch 3/200\n",
      " - 49s - loss: 3.0339 - accuracy: 0.2117\n",
      "Epoch 4/200\n",
      " - 49s - loss: 2.8739 - accuracy: 0.2592\n",
      "Epoch 5/200\n",
      " - 49s - loss: 2.7629 - accuracy: 0.2925\n",
      "Epoch 6/200\n",
      " - 49s - loss: 2.7016 - accuracy: 0.2892\n",
      "Epoch 7/200\n",
      " - 49s - loss: 2.6364 - accuracy: 0.3108\n",
      "Epoch 8/200\n",
      " - 49s - loss: 2.5511 - accuracy: 0.3192\n",
      "Epoch 9/200\n",
      " - 49s - loss: 2.4383 - accuracy: 0.3550\n",
      "Epoch 10/200\n",
      " - 49s - loss: 2.4549 - accuracy: 0.3608\n",
      "Epoch 11/200\n",
      " - 49s - loss: 2.4620 - accuracy: 0.3375\n",
      "Epoch 12/200\n",
      " - 49s - loss: 2.3845 - accuracy: 0.3617\n",
      "Epoch 13/200\n",
      " - 49s - loss: 2.3386 - accuracy: 0.3883\n",
      "Epoch 14/200\n",
      " - 49s - loss: 2.3792 - accuracy: 0.3650\n",
      "Epoch 15/200\n",
      " - 49s - loss: 2.3540 - accuracy: 0.3567\n",
      "Epoch 16/200\n",
      " - 49s - loss: 2.3343 - accuracy: 0.3808\n",
      "Epoch 17/200\n",
      " - 49s - loss: 2.2492 - accuracy: 0.3858\n",
      "Epoch 18/200\n",
      " - 49s - loss: 2.2706 - accuracy: 0.3967\n",
      "Epoch 19/200\n",
      " - 49s - loss: 2.1388 - accuracy: 0.4358\n",
      "Epoch 20/200\n",
      " - 49s - loss: 2.1417 - accuracy: 0.4425\n",
      "Epoch 21/200\n",
      " - 49s - loss: 2.1006 - accuracy: 0.4333\n",
      "Epoch 22/200\n",
      " - 49s - loss: 2.1738 - accuracy: 0.4300\n",
      "Epoch 23/200\n",
      " - 49s - loss: 2.0664 - accuracy: 0.4492\n",
      "Epoch 24/200\n",
      " - 49s - loss: 2.0717 - accuracy: 0.4400\n",
      "Epoch 25/200\n",
      " - 49s - loss: 2.1446 - accuracy: 0.4267\n",
      "Epoch 26/200\n",
      " - 49s - loss: 2.0779 - accuracy: 0.4283\n",
      "Epoch 27/200\n",
      " - 49s - loss: 2.0912 - accuracy: 0.4442\n",
      "Epoch 28/200\n",
      " - 49s - loss: 2.0052 - accuracy: 0.4675\n",
      "Epoch 29/200\n",
      " - 49s - loss: 2.0561 - accuracy: 0.4583\n",
      "Epoch 30/200\n",
      " - 49s - loss: 1.9768 - accuracy: 0.4625\n",
      "Epoch 31/200\n",
      " - 49s - loss: 2.0078 - accuracy: 0.4583\n",
      "Epoch 32/200\n",
      " - 49s - loss: 1.9718 - accuracy: 0.4683\n",
      "Epoch 33/200\n",
      " - 49s - loss: 2.0200 - accuracy: 0.4467\n",
      "Epoch 34/200\n",
      " - 49s - loss: 1.9833 - accuracy: 0.4633\n",
      "Epoch 35/200\n",
      " - 49s - loss: 1.9737 - accuracy: 0.4833\n",
      "Epoch 36/200\n",
      " - 49s - loss: 1.9971 - accuracy: 0.4642\n",
      "Epoch 37/200\n",
      " - 49s - loss: 1.9743 - accuracy: 0.4733\n",
      "Epoch 38/200\n",
      " - 49s - loss: 1.9395 - accuracy: 0.4992\n",
      "Epoch 39/200\n",
      " - 49s - loss: 1.9639 - accuracy: 0.4725\n",
      "Epoch 40/200\n",
      " - 49s - loss: 1.8343 - accuracy: 0.5092\n",
      "Epoch 41/200\n",
      " - 49s - loss: 1.8516 - accuracy: 0.5125\n",
      "Epoch 42/200\n",
      " - 49s - loss: 1.9144 - accuracy: 0.4858\n",
      "Epoch 43/200\n",
      " - 49s - loss: 1.9492 - accuracy: 0.4675\n",
      "Epoch 44/200\n",
      " - 49s - loss: 1.8836 - accuracy: 0.5042\n",
      "Epoch 45/200\n",
      " - 49s - loss: 1.9242 - accuracy: 0.4833\n",
      "Epoch 46/200\n",
      " - 49s - loss: 1.7944 - accuracy: 0.5125\n",
      "Epoch 47/200\n",
      " - 49s - loss: 1.9056 - accuracy: 0.4858\n",
      "Epoch 48/200\n",
      " - 49s - loss: 1.8640 - accuracy: 0.5100\n",
      "Epoch 49/200\n",
      " - 49s - loss: 1.8906 - accuracy: 0.4967\n",
      "Epoch 50/200\n",
      " - 49s - loss: 1.8501 - accuracy: 0.5075\n",
      "Epoch 51/200\n",
      " - 49s - loss: 1.8238 - accuracy: 0.5117\n",
      "Epoch 52/200\n",
      " - 49s - loss: 1.8162 - accuracy: 0.5083\n",
      "Epoch 53/200\n",
      " - 49s - loss: 1.7954 - accuracy: 0.5150\n",
      "Epoch 54/200\n",
      " - 49s - loss: 1.6811 - accuracy: 0.5300\n",
      "Epoch 55/200\n",
      " - 49s - loss: 1.8009 - accuracy: 0.5175\n",
      "Epoch 56/200\n",
      " - 49s - loss: 1.8253 - accuracy: 0.4933\n",
      "Epoch 57/200\n",
      " - 49s - loss: 1.9009 - accuracy: 0.4817\n",
      "Epoch 58/200\n",
      " - 49s - loss: 1.8216 - accuracy: 0.5008\n",
      "Epoch 59/200\n",
      " - 49s - loss: 1.6643 - accuracy: 0.5550\n",
      "Epoch 60/200\n",
      " - 49s - loss: 1.7763 - accuracy: 0.5283\n",
      "Epoch 61/200\n",
      " - 49s - loss: 1.7408 - accuracy: 0.5325\n",
      "Epoch 62/200\n",
      " - 49s - loss: 1.7375 - accuracy: 0.5317\n",
      "Epoch 63/200\n",
      " - 49s - loss: 1.7693 - accuracy: 0.5125\n",
      "Epoch 64/200\n",
      " - 49s - loss: 1.7468 - accuracy: 0.5408\n",
      "Epoch 65/200\n",
      " - 49s - loss: 1.6901 - accuracy: 0.5525\n",
      "Epoch 66/200\n",
      " - 50s - loss: 1.7256 - accuracy: 0.5300\n",
      "Epoch 67/200\n",
      " - 49s - loss: 1.6554 - accuracy: 0.5358\n",
      "Epoch 68/200\n",
      " - 49s - loss: 1.6756 - accuracy: 0.5350\n",
      "Epoch 69/200\n",
      " - 49s - loss: 1.6347 - accuracy: 0.5533\n",
      "Epoch 70/200\n",
      " - 49s - loss: 1.6205 - accuracy: 0.5575\n",
      "Epoch 71/200\n",
      " - 49s - loss: 1.6570 - accuracy: 0.5425\n",
      "Epoch 72/200\n",
      " - 49s - loss: 1.6291 - accuracy: 0.5475\n",
      "Epoch 73/200\n",
      " - 49s - loss: 1.6408 - accuracy: 0.5683\n",
      "Epoch 74/200\n",
      " - 49s - loss: 1.6085 - accuracy: 0.5633\n",
      "Epoch 75/200\n",
      " - 49s - loss: 1.6088 - accuracy: 0.5708\n",
      "Epoch 76/200\n",
      " - 49s - loss: 1.6609 - accuracy: 0.5525\n",
      "Epoch 77/200\n",
      " - 49s - loss: 1.6690 - accuracy: 0.5533\n",
      "Epoch 78/200\n",
      " - 49s - loss: 1.5125 - accuracy: 0.5850\n",
      "Epoch 79/200\n",
      " - 49s - loss: 1.6148 - accuracy: 0.5700\n",
      "Epoch 80/200\n",
      " - 49s - loss: 1.5840 - accuracy: 0.5808\n",
      "Epoch 81/200\n",
      " - 49s - loss: 1.5157 - accuracy: 0.5717\n",
      "Epoch 82/200\n",
      " - 49s - loss: 1.5835 - accuracy: 0.5775\n",
      "Epoch 83/200\n",
      " - 49s - loss: 1.5224 - accuracy: 0.5833\n",
      "Epoch 84/200\n",
      " - 49s - loss: 1.6431 - accuracy: 0.5542\n",
      "Epoch 85/200\n",
      " - 49s - loss: 1.6746 - accuracy: 0.5492\n",
      "Epoch 86/200\n",
      " - 49s - loss: 1.6113 - accuracy: 0.5592\n",
      "Epoch 87/200\n",
      " - 49s - loss: 1.5783 - accuracy: 0.5767\n",
      "Epoch 88/200\n",
      " - 49s - loss: 1.5837 - accuracy: 0.5583\n",
      "Epoch 89/200\n",
      " - 49s - loss: 1.4457 - accuracy: 0.5992\n",
      "Epoch 90/200\n",
      " - 49s - loss: 1.4809 - accuracy: 0.5933\n",
      "Epoch 91/200\n",
      " - 49s - loss: 1.4886 - accuracy: 0.5775\n",
      "Epoch 92/200\n",
      " - 49s - loss: 1.4147 - accuracy: 0.6125\n",
      "Epoch 93/200\n",
      " - 49s - loss: 1.4719 - accuracy: 0.5975\n",
      "Epoch 94/200\n",
      " - 49s - loss: 1.5541 - accuracy: 0.5733\n",
      "Epoch 95/200\n",
      " - 49s - loss: 1.4413 - accuracy: 0.5992\n",
      "Epoch 96/200\n",
      " - 49s - loss: 1.4492 - accuracy: 0.5992\n",
      "Epoch 97/200\n",
      " - 49s - loss: 1.3810 - accuracy: 0.6367\n",
      "Epoch 98/200\n",
      " - 49s - loss: 1.3116 - accuracy: 0.6325\n",
      "Epoch 99/200\n",
      " - 49s - loss: 1.4189 - accuracy: 0.6008\n",
      "Epoch 100/200\n",
      " - 49s - loss: 1.3605 - accuracy: 0.6375\n",
      "Epoch 101/200\n",
      " - 49s - loss: 1.4413 - accuracy: 0.5925\n",
      "Epoch 102/200\n",
      " - 49s - loss: 1.4247 - accuracy: 0.6158\n",
      "Epoch 103/200\n",
      " - 49s - loss: 1.3804 - accuracy: 0.6375\n",
      "Epoch 104/200\n",
      " - 49s - loss: 1.3652 - accuracy: 0.6475\n",
      "Epoch 105/200\n",
      " - 49s - loss: 1.3748 - accuracy: 0.6225\n",
      "Epoch 106/200\n",
      " - 48s - loss: 1.3705 - accuracy: 0.6217\n",
      "Epoch 107/200\n",
      " - 49s - loss: 1.3925 - accuracy: 0.6117\n",
      "Epoch 108/200\n",
      " - 49s - loss: 1.4289 - accuracy: 0.6233\n",
      "Epoch 109/200\n",
      " - 49s - loss: 1.3476 - accuracy: 0.6317\n",
      "Epoch 110/200\n",
      " - 49s - loss: 1.2984 - accuracy: 0.6258\n",
      "Epoch 111/200\n",
      " - 49s - loss: 1.2917 - accuracy: 0.6508\n",
      "Epoch 112/200\n",
      " - 49s - loss: 1.3092 - accuracy: 0.6475\n",
      "Epoch 113/200\n",
      " - 49s - loss: 1.2420 - accuracy: 0.6500\n",
      "Epoch 114/200\n",
      " - 49s - loss: 1.3712 - accuracy: 0.6250\n",
      "Epoch 115/200\n",
      " - 49s - loss: 1.3716 - accuracy: 0.6300\n",
      "Epoch 116/200\n",
      " - 49s - loss: 1.2887 - accuracy: 0.6325\n",
      "Epoch 117/200\n",
      " - 49s - loss: 1.3372 - accuracy: 0.6275\n",
      "Epoch 118/200\n",
      " - 49s - loss: 1.4045 - accuracy: 0.6167\n",
      "Epoch 119/200\n",
      " - 49s - loss: 1.2994 - accuracy: 0.6508\n",
      "Epoch 120/200\n",
      " - 49s - loss: 1.3211 - accuracy: 0.6508\n",
      "Epoch 121/200\n",
      " - 49s - loss: 1.2896 - accuracy: 0.6492\n",
      "Epoch 122/200\n",
      " - 49s - loss: 1.3984 - accuracy: 0.6283\n",
      "Epoch 123/200\n",
      " - 49s - loss: 1.2664 - accuracy: 0.6633\n",
      "Epoch 124/200\n",
      " - 49s - loss: 1.2704 - accuracy: 0.6583\n",
      "Epoch 125/200\n",
      " - 49s - loss: 1.2429 - accuracy: 0.6583\n",
      "Epoch 126/200\n",
      " - 49s - loss: 1.2281 - accuracy: 0.6775\n",
      "Epoch 127/200\n",
      " - 49s - loss: 1.3261 - accuracy: 0.6475\n",
      "Epoch 128/200\n",
      " - 49s - loss: 1.2320 - accuracy: 0.6608\n",
      "Epoch 129/200\n",
      " - 49s - loss: 1.2616 - accuracy: 0.6542\n",
      "Epoch 130/200\n",
      " - 49s - loss: 1.2566 - accuracy: 0.6600\n",
      "Epoch 131/200\n",
      " - 49s - loss: 1.2986 - accuracy: 0.6583\n",
      "Epoch 132/200\n",
      " - 49s - loss: 1.2905 - accuracy: 0.6600\n",
      "Epoch 133/200\n",
      " - 49s - loss: 1.2450 - accuracy: 0.6658\n",
      "Epoch 134/200\n",
      " - 49s - loss: 1.1981 - accuracy: 0.6733\n",
      "Epoch 135/200\n",
      " - 49s - loss: 1.2282 - accuracy: 0.6425\n",
      "Epoch 136/200\n",
      " - 49s - loss: 1.1865 - accuracy: 0.6842\n",
      "Epoch 137/200\n",
      " - 49s - loss: 1.2394 - accuracy: 0.6542\n",
      "Epoch 138/200\n",
      " - 49s - loss: 1.2232 - accuracy: 0.6700\n",
      "Epoch 139/200\n",
      " - 49s - loss: 1.2083 - accuracy: 0.6675\n",
      "Epoch 140/200\n",
      " - 49s - loss: 1.2674 - accuracy: 0.6600\n",
      "Epoch 141/200\n",
      " - 49s - loss: 1.2337 - accuracy: 0.6683\n",
      "Epoch 142/200\n",
      " - 49s - loss: 1.2784 - accuracy: 0.6467\n",
      "Epoch 143/200\n",
      " - 49s - loss: 1.2816 - accuracy: 0.6483\n",
      "Epoch 144/200\n",
      " - 49s - loss: 1.2185 - accuracy: 0.6683\n",
      "Epoch 145/200\n",
      " - 49s - loss: 1.1817 - accuracy: 0.6775\n",
      "Epoch 146/200\n",
      " - 49s - loss: 1.2254 - accuracy: 0.6600\n",
      "Epoch 147/200\n",
      " - 49s - loss: 1.1959 - accuracy: 0.6808\n",
      "Epoch 148/200\n",
      " - 49s - loss: 1.1687 - accuracy: 0.6750\n",
      "Epoch 149/200\n",
      " - 49s - loss: 1.1213 - accuracy: 0.6925\n",
      "Epoch 150/200\n",
      " - 49s - loss: 1.2324 - accuracy: 0.6542\n",
      "Epoch 151/200\n",
      " - 49s - loss: 1.1868 - accuracy: 0.6667\n",
      "Epoch 152/200\n",
      " - 49s - loss: 1.1110 - accuracy: 0.7000\n",
      "Epoch 153/200\n",
      " - 49s - loss: 1.1368 - accuracy: 0.6792\n",
      "Epoch 154/200\n",
      " - 49s - loss: 1.1793 - accuracy: 0.6825\n",
      "Epoch 155/200\n",
      " - 49s - loss: 1.0939 - accuracy: 0.7025\n",
      "Epoch 156/200\n",
      " - 49s - loss: 1.1661 - accuracy: 0.6833\n",
      "Epoch 157/200\n",
      " - 49s - loss: 1.1904 - accuracy: 0.6792\n",
      "Epoch 158/200\n",
      " - 49s - loss: 1.2173 - accuracy: 0.6867\n",
      "Epoch 159/200\n",
      " - 49s - loss: 1.1363 - accuracy: 0.6850\n",
      "Epoch 160/200\n",
      " - 49s - loss: 1.0913 - accuracy: 0.7033\n",
      "Epoch 161/200\n",
      " - 49s - loss: 1.2207 - accuracy: 0.6592\n",
      "Epoch 162/200\n",
      " - 49s - loss: 1.1192 - accuracy: 0.6850\n",
      "Epoch 163/200\n",
      " - 49s - loss: 1.1915 - accuracy: 0.6850\n",
      "Epoch 164/200\n",
      " - 49s - loss: 1.1173 - accuracy: 0.6967\n",
      "Epoch 165/200\n",
      " - 49s - loss: 1.1696 - accuracy: 0.6700\n",
      "Epoch 166/200\n",
      " - 49s - loss: 1.1330 - accuracy: 0.6675\n",
      "Epoch 167/200\n",
      " - 49s - loss: 1.0730 - accuracy: 0.7058\n",
      "Epoch 168/200\n",
      " - 49s - loss: 1.1714 - accuracy: 0.6983\n",
      "Epoch 169/200\n",
      " - 49s - loss: 1.1332 - accuracy: 0.6825\n",
      "Epoch 170/200\n",
      " - 49s - loss: 1.2053 - accuracy: 0.6800\n",
      "Epoch 171/200\n",
      " - 49s - loss: 1.0206 - accuracy: 0.7233\n",
      "Epoch 172/200\n",
      " - 49s - loss: 1.0816 - accuracy: 0.7025\n",
      "Epoch 173/200\n",
      " - 49s - loss: 1.1119 - accuracy: 0.6958\n",
      "Epoch 174/200\n",
      " - 49s - loss: 1.0457 - accuracy: 0.6967\n",
      "Epoch 175/200\n",
      " - 49s - loss: 1.0799 - accuracy: 0.6958\n",
      "Epoch 176/200\n",
      " - 49s - loss: 1.0852 - accuracy: 0.6983\n",
      "Epoch 177/200\n",
      " - 49s - loss: 1.0929 - accuracy: 0.6967\n",
      "Epoch 178/200\n",
      " - 49s - loss: 1.0603 - accuracy: 0.7175\n",
      "Epoch 179/200\n",
      " - 49s - loss: 1.0374 - accuracy: 0.7133\n",
      "Epoch 180/200\n",
      " - 49s - loss: 1.0956 - accuracy: 0.7083\n",
      "Epoch 181/200\n",
      " - 49s - loss: 1.0553 - accuracy: 0.7158\n",
      "Epoch 182/200\n",
      " - 49s - loss: 1.0498 - accuracy: 0.7183\n",
      "Epoch 183/200\n",
      " - 49s - loss: 1.0094 - accuracy: 0.7267\n",
      "Epoch 184/200\n",
      " - 49s - loss: 1.0683 - accuracy: 0.7058\n",
      "Epoch 185/200\n",
      " - 49s - loss: 1.0336 - accuracy: 0.7217\n",
      "Epoch 186/200\n",
      " - 49s - loss: 1.0672 - accuracy: 0.7142\n",
      "Epoch 187/200\n",
      " - 49s - loss: 0.9876 - accuracy: 0.7192\n",
      "Epoch 188/200\n",
      " - 49s - loss: 1.0166 - accuracy: 0.7158\n",
      "Epoch 189/200\n",
      " - 49s - loss: 1.0492 - accuracy: 0.7075\n",
      "Epoch 190/200\n",
      " - 49s - loss: 1.0283 - accuracy: 0.7108\n",
      "Epoch 191/200\n",
      " - 49s - loss: 0.9556 - accuracy: 0.7250\n",
      "Epoch 192/200\n",
      " - 49s - loss: 1.0183 - accuracy: 0.7233\n",
      "Epoch 193/200\n",
      " - 49s - loss: 1.1251 - accuracy: 0.6817\n",
      "Epoch 194/200\n",
      " - 49s - loss: 1.0502 - accuracy: 0.7150\n",
      "Epoch 195/200\n",
      " - 49s - loss: 1.0340 - accuracy: 0.7225\n",
      "Epoch 196/200\n",
      " - 49s - loss: 1.1075 - accuracy: 0.6875\n",
      "Epoch 197/200\n",
      " - 49s - loss: 1.0465 - accuracy: 0.7083\n",
      "Epoch 198/200\n",
      " - 49s - loss: 1.0286 - accuracy: 0.7117\n",
      "Epoch 199/200\n",
      " - 49s - loss: 0.9986 - accuracy: 0.7083\n",
      "Epoch 200/200\n",
      " - 49s - loss: 0.9639 - accuracy: 0.7367\n",
      "Final model parameters set to stochastic weight average.\n",
      "Final stochastic averaged weights saved to file.\n"
     ]
    }
   ],
   "source": [
    "input_shape=(HEIGHT, WIDTH, 3) # rgb aja, a nya ilangin\n",
    "\n",
    "dropout = 0.4\n",
    "epochs = 200\n",
    "swa = SWA('./keras_swa.model',epochs-3)\n",
    "\n",
    "base_model = efn.EfficientNetB3(weights='imagenet',\n",
    "                            include_top=False,\n",
    "                            input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      num_classes=42)\n",
    "\n",
    "finetune_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-3)\n",
    "\n",
    "history = finetune_model.fit_generator(generator=train_generator,\n",
    "                                        validation_data=validation_generator,\n",
    "                                        steps_per_epoch=150,\n",
    "                                        epochs=epochs,\n",
    "                                       verbose=2,\n",
    "                                       validation_steps=55,\n",
    "                                       callbacks=snapshot.get_callbacks())\n",
    "\n",
    "try:\n",
    "    finetune_model.load_weights('./keras_swa.model')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8c37556c587f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-0359f2a90bcd>\u001b[0m in \u001b[0;36mplot_loss_acc\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b5_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      " 13991936/115515256 [==>...........................] - ETA: 14s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-50aec2f10e40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m base_model = efn.EfficientNetB5(weights='imagenet',\n\u001b[1;32m      4\u001b[0m                             \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                             input_shape=(HEIGHT, WIDTH, 3))\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m finetune_model = build_finetune_model(base_model, \n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'utils'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet/model.py\u001b[0m in \u001b[0;36mEfficientNetB5\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0minput_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpooling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m     )\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/efficientnet/model.py\u001b[0m in \u001b[0;36mEfficientNet\u001b[0;34m(width_coefficient, depth_coefficient, default_resolution, dropout_rate, drop_connect_rate, depth_divisor, blocks_args, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mIMAGENET_WEIGHTS_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'models'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         )\n\u001b[1;32m    438\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1012\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1013\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read on closed or unwrapped SSL socket.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \"\"\"\n\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "swa = SWA('./keras_swab5.model',epochs-3)\n",
    "\n",
    "base_model = efn.EfficientNetB5(weights='imagenet',\n",
    "                            include_top=False,\n",
    "                            input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=dropout, \n",
    "                                      num_classes=42)\n",
    "\n",
    "finetune_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-3)\n",
    "\n",
    "history = finetune_model.fit_generator(generator=train_generator,\n",
    "                                        validation_data=validation_generator,\n",
    "                                        steps_per_epoch=150,\n",
    "                                        epochs=epochs,\n",
    "                                       verbose=2,\n",
    "                                       validation_steps=55,\n",
    "                                       callbacks=snapshot.get_callbacks())\n",
    "\n",
    "try:\n",
    "    finetune_model.load_weights('./keras_swab5.model')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "258441216/258434480 [==============================] - 88s 0us/step\n",
      "Stochastic weight averaging selected for last 3 epochs.\n",
      "Epoch 1/200\n",
      " - 249s - loss: 3.9526 - accuracy: 0.0650\n",
      "Epoch 2/200\n",
      " - 150s - loss: 3.6872 - accuracy: 0.0983\n",
      "Epoch 3/200\n",
      " - 151s - loss: 3.4377 - accuracy: 0.1300\n",
      "Epoch 4/200\n",
      " - 152s - loss: 3.3597 - accuracy: 0.1467\n",
      "Epoch 5/200\n",
      " - 152s - loss: 3.2340 - accuracy: 0.1658\n",
      "Epoch 6/200\n",
      " - 151s - loss: 3.0782 - accuracy: 0.1975\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[8,2560,10,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/avg_pool_1/AvgPool_grad/AvgPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b0c693f04fdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                                        \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                                        callbacks=snapshot.get_callbacks())\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[8,2560,10,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node training_1/Adam/gradients/avg_pool_1/AvgPool_grad/AvgPoolGrad}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "swa = SWA('./keras_swab7.model',epochs-3)\n",
    "\n",
    "base_model = efn.EfficientNetB7(weights='imagenet',\n",
    "                            include_top=False,\n",
    "                            input_shape=(HEIGHT, WIDTH, 3))\n",
    "\n",
    "finetune_model = build_finetune_model(base_model, \n",
    "                                      dropout=0.4, \n",
    "                                      num_classes=42)n\n",
    "\n",
    "finetune_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "snapshot = SnapshotCallbackBuilder(nb_epochs=epochs,nb_snapshots=1,init_lr=1e-3)\n",
    "\n",
    "history = finetune_model.fit_generator(generator=train_generator,\n",
    "                                        validation_data=validation_generator,\n",
    "                                        steps_per_epoch=150,\n",
    "                                        epochs=epochs,\n",
    "                                       verbose=2,\n",
    "                                       validation_steps=55,\n",
    "                                       callbacks=snapshot.get_callbacks())\n",
    "\n",
    "try:\n",
    "    finetune_model.load_weights('./keras_swab7.model')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
